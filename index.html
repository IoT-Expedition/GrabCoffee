<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Grabcoffee by IoT-Expedition</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Grabcoffee</h1>
        <p></p>

        <p class="view"><a href="https://github.com/IoT-Expedition/GrabCoffee">View the Project on GitHub <small>IoT-Expedition/GrabCoffee</small></a></p>


        <ul>
          <li><a href="https://github.com/IoT-Expedition/GrabCoffee/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/IoT-Expedition/GrabCoffee/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/IoT-Expedition/GrabCoffee">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <p>Welcome to the GrabCoffee wiki!</p>

<p>To make this demo work, you need to first upload the Amazon Alexa Skills to your AWS server to handle requests of human speech. Go to <a href="https://github.com/IoT-Expedition/GrabCoffee/wiki/Uploading-Alexa-Skills-to-AWS-server">New Page
Uploading Alexa Skills to AWS server</a> to see how to do this. </p>

<p>The rest is a dashboard where you can tweak parameters of factors affecting whether you might or might not be able to grab a coffee before your next meeting. Once you drag the meeting coordinator icon, his location will be updated to the BuildingDepot server. The transportation modes of both you and your meeting coordinator can be changed to see different scenarios as well. You can even update the begin time of your next event in your calendar in the Google Calendar. </p>

<p>The dashboard requires three Google APIs enabled to work properly. Go to <a href="https://github.com/IoT-Expedition/GrabCoffee/wiki/Setup-Required-Google-APIs-for-Dashboard">Setup Required Google APIs for Dashboard</a> to see how to do this. </p>

<p><img src="https://googledrive.com/host/0B3jZo6rKlGb4WlFkTHRmaXcwRFk/web_interface.png" alt="alt tag"></p>

<p>This demo has two components: 1. Alexa Skills, 2. Dashboard. Before running the demo, make sure you've gone through the setup for </p>

<p><a href="https://github.com/IoT-Expedition/GrabCoffee/wiki/Uploading-Alexa-Skills-to-AWS-server">Uploading Alexa Skills to AWS server</a>
<a href="https://github.com/IoT-Expedition/GrabCoffee/wiki/Setup-Required-Google-APIs-for-Dashboard">Setup Required Google APIs for Dashboard</a></p>

<p>Once you finished setting up on the Alexa Skill and the dashboard required APIs, you are good to run the demo. In the Dashboard directory on your PC, run </p>

<p><code>http-server -p 8000</code> </p>

<p>and type localhost:8000 in the Chrome. </p>

<p>One thing to note that you need to authorize the access to Google Calendar API the first time you run the demo. </p>

<p><img src="https://googledrive.com/host/0B3jZo6rKlGb4WlFkTHRmaXcwRFk/authorize.png" alt="alt tag"></p>

<hr>

<p>Alexa Skills Kit is a voice interaction service offered by Amazon. It is used through the Amazon Echo Device. 
<a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit">https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit</a></p>

<p>Lambda Function refers to the Node.js function located in AWS Lambda. The function can be written in Node.js or Java.
<a href="https://console.aws.amazon.com/lambda">https://console.aws.amazon.com/lambda</a></p>

<p>The Alexa Skill is the Skill that we create that specifies the type of commands, their structure, number of inputs, sample utterances of the commands, etc.
<a href="https://developer.amazon.com/edw/home.html#/">https://developer.amazon.com/edw/home.html#/</a></p>

<p>When we wake Alexa using the "Wake Word" (either "Alexa" or "Amazon", which can be changed in the Alexa Phone Application settings), it starts to stream the audio to the Alexa Skill for voice recognition. Once the command given by the User is identified, it sends a JSON Request to the Lambda Function, specifying the type of command. The Lambda Function processes the request as required, connecting to the Database or any other Web Services, and it formats a Response. The response must have a SpeechText which is the text that the Echo Device responds with. The Lambda Function can also send an optional Card that is sent to the Alexa Mobile Application. This can be used to present more detailed information that is too complex for the Echo Device to just talk back. The Lambda Function sends this response to the Alexa Service which automatically sends it back to the Echo Device which speaks the text it received as the SpeechText. 
This response is of two types, it can either "Ask" or "Tell": 
Tell means it can either just say the response and end its session and to interact again we need to invoke it again. 
Ask means it can give the response and wait for the user's next command to proceed. </p>

<p>This is the general working of the Alexa Skill. In this, we develop the Lambda Function that processes the request of the user and formats the response. The Speech-to-Text and Text-to-Speech part is automated so we need not worry about that. This function needs to be created/edited in the local machine either in a Text Editor/IDE. </p>

<p>By now the following terms should be clear:
Alexa Skill
Lambda Function
Amazon Echo Device</p>

<p><img src="https://lh5.googleusercontent.com/jUswUfIXG6t81HK4YaZee0P3W9jvWaASQJMGp9nM5LDJnDwOicQ7BZHu3SeoyrfokfdvJnpVG6SoFPp54Ag_jNkh1VGLUUeK-fPwtaju19nK033r7WbSC9x0SLEI6dk4A7xnJ0qJDmy5WDOqAw" alt="alt tag"></p>

<p>The Lambda Function Homepage. Choose which Lambda Function which you need to change or you can create a new Function also.</p>

<p><img src="https://lh5.googleusercontent.com/jUswUfIXG6t81HK4YaZee0P3W9jvWaASQJMGp9nM5LDJnDwOicQ7BZHu3SeoyrfokfdvJnpVG6SoFPp54Ag_jNkh1VGLUUeK-fPwtaju19nK033r7WbSC9x0SLEI6dk4A7xnJ0qJDmy5WDOqAw" alt="alt tag"></p>

<p>This is the page of the selected Lambda Function. Here you can
Upload new code for the function
Change configurations of the function
Edit the Event Sources
Test the Lambda Function by giving it sample inputs and view the execution results of the Lambda Function.
Identify syntax errors or logical errors through the "Log output" section.</p>

<p><img src="https://photos-1.dropbox.com/t/2/AAAJYN6dnv3EGBasOiUwZeuA-WS1m6cj4puDXdgWtTAOIw/12/105186450/png/32x32/1/_/1/2/Screen%20Shot%202016-03-27%20at%206.06.51%20PM.png/EN_LtlEYm7t5IAIoAg/ZP8A4MdqgaXKes5PCkNnYenPTld2J3hep0gvPexoymY?size=1024x768&amp;size_mode=3" alt="alt tag"></p>

<p>The Execution result section shows the JSON Response of the Lambda function. The SpeechText and the Card details can be viewed in this. Also the session_attributes that are used in the function are displayed.</p>

<p>The Log output section shows the text that we log in the code and if there is an error in the Lambda Function, it will be displayed here with the Line number for easy identification of the error.</p>

<p>The Summary section mainly shows that Duration of Execution and the memory used for the execution.</p>

<p><img src="https://lh3.googleusercontent.com/4C635ydN1CwhTlUa8Z4NtgIj5iMtZ4KKL_ZCcFnBYmyI4G4Z_N-LWcUmcpLf5KmNBWKBtfTTxUvVaTFD1hNUnlb6B21ILTcPh-KEom2g1Vvw3KJKzarCKoVp2SYHpWpqi4BoNTNqb-uR0iBVbw" alt="alt tag"></p>

<p>By clicking "Actions" button near the "Test" button, and choosing "edit sample event" the above screen is displayed. We can edit the JSON request that is sent to the Lambda Function and change the Intent, slots for the intent, etc. </p>

<p><img src="https://lh5.googleusercontent.com/frONBqOE5_NPC4UVSRZDfn3zjhOAj00fPKFIn28fos1ADv2EdhgDwobkYOUKiOx7mksYnTS9smy74pBXNv0SOgiucquYUjC2x6JKRIog5UHzRi6HxfNT5rSz3g5CjzcEkVcv7Sdw6TfzagMggQ" alt="alt tag"></p>

<p>This is the configuration window. Here we can specify different roles for the Function to give it more access to other AWS Functionalities. (Not important right now)</p>

<p><img src="https://lh3.googleusercontent.com/F0PCrWTYYyL0k4_jC7KqgNKWlH9Saah4LRb9osia8jpJge_T9fcz5q_wkokLOUtmVdt7X22_p-oqaQ-D-vtZstIcM2BdbklmgI-3At0p58KnehS8xc6MOOuqmvHBgcDxhu1QXm3b2ltSZ-tsmg" alt="alt tag"></p>

<p>This screen displays the Event sources for the Lambda Function. Without giving the Alexa Skills Kit event source, you will not be able to link the Alexa Skill with this Lambda Function. </p>

<p><img src="https://lh4.googleusercontent.com/r7Y2Q4EyK4lrS01VOensyhl2JfpNzgICVP3ECYH5U-_gpJzntglcBl7b9EdXeKI_B7-EJoeFgXiykzfYX3JePI24mRj11Jc9x7znvOrANVoFybAIwJJ5wyYV2GFRqm9FqWAzuBT9_bjk-QJPqA" alt="alt tag"></p>

<p>This is the homepage of the Alexa Skills Kit. We need to choose "Get Started &gt;" on the Alexa Skills Kit. </p>

<p><img src="https://lh4.googleusercontent.com/3KZr5p6MLFtcHgUpY8LrJkbkqwXxvy7X3oesKClIk_246jP8GmHsHu5e2Z7K49yzw0tQWK6OPxx4rdLuJzDA8ARP79kXKiWOgcY36spgxCREsI-GkTlpkGR6CySjicfo4jG7nQcM-BUbdUz5qg" alt="alt tag"></p>

<p>This page lists all the Alexa Skills that our account currently has (For now just 1). Choose Edit to change the Skill.</p>

<p><img src="https://lh4.googleusercontent.com/JDMP6Jta2nZciUv6grRQ1wSRtHYsTNd7qLbE3U1OAPE2WEEvCHYLfSVUd0lSThUjPvsW1NF1D6dbtrlgVuFBLggWVcgJYV8ODGmtPjr9goH_fBlfB_vIqE0wZGX2c7ScMR0gvs6S-1Jy1RkZEw" alt="alt tag"></p>

<p>This is the Skill Information page of the selected skill. Here the name, version, etc. are displayed. The Invocation name means the name that is used to call the function by the User. The Endpoint must specify the Lambda Function that is associated with this Skill.</p>

<p><img src="https://lh5.googleusercontent.com/TKWwij6biJxMBkoYqql56Qtpka_aeZlcsHSz3O926ISSMyvn-QgUNX2dHc6AZ1E4fCJj9slyUmkq-dSfdUu9k9yuDEbeFxUY9I-ObkXzbfFQAWOMeWBaqC6Oznpmf3Yi5ddIbnqyY78KlHjddg" alt="alt tag"></p>

<p>This page shows the Intent Schema section. We need to specify a schema for all the intents that we specify whether they accept inputs or not and what types of inputs they accept. The Custom Slot Types can be used to specify new types of input types(Not important right now). The Sample Utterances section is used to enter all the sample utterances for each of the intent that the user may give. This is to make the Alexa Service better understand which intent the user is specifying.</p>

<p>In the next page, we can test the Skill by giving the text of the speech that the user gives and it displays the JSON Request and Response sent to the Lambda Function. We need to set the "Enabled" option for us to test the skill. The "Enabled" option is in the same page.</p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/IoT-Expedition">IoT-Expedition</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
